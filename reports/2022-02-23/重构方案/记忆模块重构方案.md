# 记忆模块重构方案

**创建日期**: 2026-02-23  
**作者**: GLM-5  
**状态**: 方案设计阶段

---

## 一、问题分析

### 1.1 文件概览

```
/Users/ray/projects/mindx/mindx/internal/usecase/memory/memory.go
├── 总行数: 1003 行
├── 方法数: 28 个
├── 结构体: 1 个 (Memory)
└── 依赖项: 6 个
```

### 1.2 职责分析

当前 `Memory` 结构体承担了 **8 大类职责**：

```
┌─────────────────────────────────────────────────────────────────────┐
│                    Memory 结构体职责分布                             │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  1. 核心业务 (4 方法)                                         │   │
│  │     Record, Search, Optimize, ClusterConversations           │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  2. 权重计算 (5 方法)                                         │   │
│  │     calculateTimeWeight, calculateRepeatWeight,              │   │
│  │     calculateEmphasisWeight, calculateTotalWeight,           │   │
│  │     DecayWeights                                             │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  3. LLM 调用 (2 方法)                                         │   │
│  │     generateSummary, generateKeywords                        │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  4. 存储操作 (4 方法)                                         │   │
│  │     storeMemory, getAllMemories, parseMemoryPoint,           │   │
│  │     generateMemoryKey                                        │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  5. 搜索辅助 (3 方法)                                         │   │
│  │     filterByKeywords, sortByWeight, calculateKeywordSimilarity│  │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  6. 聚类处理 (3 方法)                                         │   │
│  │     determineOptimalK, generateCombinedMemoryPoint,          │   │
│  │     extractConversationContent                               │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  7. 维护操作 (3 方法)                                         │   │
│  │     CleanupExpiredMemories, StartPeriodicMaintenance,        │   │
│  │     AdjustMemoryWeight                                       │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │  8. 工具方法 (4 方法)                                         │   │
│  │     simpleTokenize, calculateCosineSimilarity, Close,        │   │
│  │     DeduplicateMemory                                        │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

### 1.3 问题清单

| 问题                 | 影响                               | 行数范围 | 严重程度 |
| -------------------- | ---------------------------------- | -------- | -------- |
| **单一职责原则违反** | 难以理解、测试、维护               | 全文件   | 高       |
| **方法过长**         | `ClusterConversations` 超过 150 行 | 542-716  | 高       |
| **依赖过多**         | 6 个依赖，耦合度高                 | 24-30    | 中       |
| **重复代码**         | 多处 `getAllMemories` + 遍历模式   | 多处     | 中       |
| **职责不清**         | 权重计算、LLM调用、聚类混杂        | 全文件   | 高       |
| **测试困难**         | 需要 Mock 多个依赖                 | -        | 高       |
| **命名不一致**       | `calculateXxx` vs `generateXxx`    | 多处     | 低       |

### 1.4 代码异味检测

```go
// 异味1: 方法过长 (150+ 行)
func (m *Memory) ClusterConversations(conversations []entity.ConversationLog) error {
    // 150+ 行代码，包含：
    // - 内容提取
    // - 关键词生成
    // - 摘要生成
    // - 向量生成
    // - K-Means 聚类
    // - 结果存储
}

// 异味2: 重复的数据获取模式
func (m *Memory) CleanupExpiredMemories() error {
    allMemories, err := m.getAllMemories()  // 重复
    // ...
}

func (m *Memory) AdjustMemoryWeight(id int, multiple float64) error {
    allMemories, err := m.getAllMemories()  // 重复
    // ...
}

func (m *Memory) DecayWeights() error {
    allMemories, err := m.getAllMemories()  // 重复
    // ...
}

// 异味3: 多层嵌套
func (m *Memory) ClusterConversations(conversations []entity.ConversationLog) error {
    if len(memoryPoints) >= 2 {
        if len(points) >= 2 {
            for cid, cluster := range kmClusters {
                for _, obs := range cluster.Observations {
                    for pointIdx, memIdx := range pointIndices {
                        // 4 层嵌套
                    }
                }
            }
        }
    }
}

// 异味4: 硬编码配置
func (m *Memory) calculateEmphasisWeight(text string) float64 {
    emphasisLevels := map[string]float64{
        "务必":  0.4,  // 硬编码
        "关键":  0.35,
        // ...
    }
}
```

---

## 二、重构目标

### 2.1 设计原则

| 原则               | 应用                         |
| ------------------ | ---------------------------- |
| **单一职责 (SRP)** | 每个模块只负责一类功能       |
| **开放封闭 (OCP)** | 通过接口扩展，不修改现有实现 |
| **依赖倒置 (DIP)** | 依赖抽象接口，不依赖具体实现 |
| **接口隔离 (ISP)** | 细粒度接口，避免臃肿         |

### 2.2 重构目标

| 指标       | 重构前  | 重构后   |
| ---------- | ------- | -------- |
| 单文件行数 | 1003 行 | < 200 行 |
| 单方法行数 | 150+ 行 | < 30 行  |
| 职责数量   | 8 类    | 1 类     |
| 依赖数量   | 6 个    | 2-3 个   |
| 测试复杂度 | 高      | 低       |

---

## 三、架构设计

### 3.1 模块拆分方案

```
┌─────────────────────────────────────────────────────────────────────┐
│                      重构后模块架构                                  │
│                                                                      │
│                         ┌─────────────────┐                         │
│                         │     Memory      │                         │
│                         │   (门面/协调器)  │                         │
│                         └────────┬────────┘                         │
│                                  │                                   │
│           ┌──────────────────────┼──────────────────────┐           │
│           │                      │                      │           │
│           ▼                      ▼                      ▼           │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐     │
│  │  MemoryRecorder │  │  MemorySearcher │  │ MemoryOptimizer │     │
│  │   (记录服务)    │  │   (搜索服务)    │  │   (优化服务)    │     │
│  └────────┬────────┘  └────────┬────────┘  └────────┬────────┘     │
│           │                      │                      │           │
│           └──────────────────────┼──────────────────────┘           │
│                                  │                                   │
│           ┌──────────────────────┼──────────────────────┐           │
│           │                      │                      │           │
│           ▼                      ▼                      ▼           │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐     │
│  │ WeightCalculator│  │ ContentProcessor│  │ MemoryClusterer│     │
│  │  (权重计算器)   │  │  (内容处理器)   │  │  (聚类处理器)   │     │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘     │
│                                                                      │
│                                  │                                   │
│                                  ▼                                   │
│                         ┌─────────────────┐                         │
│                         │   core.Store    │                         │
│                         │   (存储抽象)    │                         │
│                         └─────────────────┘                         │
└─────────────────────────────────────────────────────────────────────┘
```

### 3.2 目录结构

```
internal/usecase/memory/
├── memory.go              # 门面模式，协调各服务 (~150 行)
├── recorder.go            # 记录服务 (~100 行)
├── searcher.go            # 搜索服务 (~100 行)
├── optimizer.go           # 优化服务 (~80 行)
├── weight/
│   ├── calculator.go      # 权重计算器接口 (~30 行)
│   ├── time_weight.go     # 时间权重计算 (~50 行)
│   ├── repeat_weight.go   # 重复权重计算 (~60 行)
│   ├── emphasis_weight.go # 强调权重计算 (~50 行)
│   └── config.go          # 权重配置 (~40 行)
├── processor/
│   ├── content.go         # 内容处理器接口 (~30 行)
│   ├── summarizer.go      # 摘要生成器 (~60 行)
│   └── keyword_extractor.go # 关键词提取器 (~70 行)
├── cluster/
│   ├── clusterer.go       # 聚类器接口 (~30 行)
│   ├── kmeans.go          # K-Means 实现 (~120 行)
│   └── combined_point.go  # 组合记忆点生成 (~80 行)
├── dedup/
│   └── deduplicator.go    # 去重处理器 (~60 行)
└── maintenance/
    ├── cleaner.go         # 清理服务 (~60 行)
    └── scheduler.go       # 定时维护 (~50 行)
```

---

## 四、核心接口设计

### 4.1 权重计算器

```go
package weight

import "time"

type WeightCalculator interface {
    CalculateTimeWeight(createdAt time.Time) float64
    CalculateRepeatWeight(content string, keywords []string) float64
    CalculateEmphasisWeight(content string) float64
    CalculateTotalWeight(timeWeight, repeatWeight, emphasisWeight float64, scene string) float64
}

type WeightConfig struct {
    TimeDecayFactor    float64
    RepeatBonusFactor  float64
    MaxRepeatWeight    float64
    EmphasisKeywords   map[string]float64
    SceneRatios        map[string]SceneRatio
}

type SceneRatio struct {
    TimeRatio     float64
    EmphasisRatio float64
    RepeatRatio   float64
}

type Calculator struct {
    config WeightConfig
    store  core.Store
}

func NewCalculator(config WeightConfig, store core.Store) *Calculator {
    return &Calculator{
        config: config,
        store:  store,
    }
}

func (c *Calculator) CalculateTimeWeight(createdAt time.Time) float64 {
    days := time.Since(createdAt).Hours() / 24
    if days <= 3 {
        return 1.0 / (1.0 + c.config.TimeDecayFactor*days)
    }
    return 1.0 / (1.0 + c.config.TimeDecayFactor*0.3*days)
}

func (c *Calculator) CalculateRepeatWeight(content string, keywords []string) float64 {
    if c.store == nil {
        return 1.0
    }

    allMemories, _ := c.store.Search(nil, 1000)
    repeatCount := c.countRepeats(content, keywords, allMemories)

    weight := 1.0 + float64(repeatCount)*c.config.RepeatBonusFactor
    if weight > c.config.MaxRepeatWeight {
        weight = c.config.MaxRepeatWeight
    }
    return weight
}

func (c *Calculator) CalculateEmphasisWeight(content string) float64 {
    contentLower := strings.ToLower(content)
    maxWeight := 0.2

    for keyword, weight := range c.config.EmphasisKeywords {
        if strings.Contains(contentLower, strings.ToLower(keyword)) && weight > maxWeight {
            maxWeight = weight
        }
    }

    if strings.Contains(content, "！") || strings.Contains(content, "!!") {
        maxWeight += 0.05
    }

    return maxWeight
}

func (c *Calculator) CalculateTotalWeight(timeWeight, repeatWeight, emphasisWeight float64, scene string) float64 {
    ratio, ok := c.config.SceneRatios[scene]
    if !ok {
        ratio = c.config.SceneRatios["default"]
    }

    return timeWeight*ratio.TimeRatio +
           emphasisWeight*ratio.EmphasisRatio +
           repeatWeight*ratio.RepeatRatio
}
```

### 4.2 内容处理器

```go
package processor

import "context"

type ContentProcessor interface {
    GenerateSummary(ctx context.Context, text string) (string, error)
    ExtractKeywords(ctx context.Context, text string) ([]string, error)
}

type LLMContentProcessor struct {
    client       *openai.Client
    summaryModel string
    keywordModel string
    logger       logging.Logger
}

func NewLLMContentProcessor(client *openai.Client, summaryModel, keywordModel string, logger logging.Logger) *LLMContentProcessor {
    return &LLMContentProcessor{
        client:       client,
        summaryModel: summaryModel,
        keywordModel: keywordModel,
        logger:       logger,
    }
}

func (p *LLMContentProcessor) GenerateSummary(ctx context.Context, text string) (string, error) {
    if p.client == nil {
        return p.truncateText(text, 200), nil
    }

    resp, err := p.client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
        Model: p.summaryModel,
        Messages: []openai.ChatCompletionMessage{
            {Role: openai.ChatMessageRoleSystem, Content: "请将以下对话内容精炼成一段简洁的摘要，保留关键信息："},
            {Role: openai.ChatMessageRoleUser, Content: text},
        },
    })

    if err != nil || len(resp.Choices) == 0 {
        return p.truncateText(text, 200), nil
    }

    return resp.Choices[0].Message.Content, nil
}

func (p *LLMContentProcessor) ExtractKeywords(ctx context.Context, text string) ([]string, error) {
    if p.client == nil {
        return p.simpleTokenize(text), nil
    }

    resp, err := p.client.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
        Model: p.keywordModel,
        Messages: []openai.ChatCompletionMessage{
            {Role: openai.ChatMessageRoleSystem, Content: "请从以下对话内容中提取 3-5 个最重要的关键词："},
            {Role: openai.ChatMessageRoleUser, Content: text},
        },
        ResponseFormat: &openai.ChatCompletionResponseFormat{
            Type: openai.ChatCompletionResponseFormatTypeJSONSchema,
            JSONSchema: &openai.ChatCompletionResponseFormatJSONSchema{
                Name:   "keywords",
                Schema: p.buildKeywordsSchema(),
                Strict: true,
            },
        },
    })

    if err != nil || len(resp.Choices) == 0 {
        return p.simpleTokenize(text), nil
    }

    return p.parseKeywords(resp.Choices[0].Message.Content)
}

func (p *LLMContentProcessor) truncateText(text string, maxLen int) string {
    if len(text) > maxLen {
        return text[:maxLen] + "..."
    }
    return text
}

func (p *LLMContentProcessor) simpleTokenize(text string) []string {
    tokens := strings.Fields(text)
    var keywords []string

    for _, token := range tokens {
        token = strings.Trim(token, "，。！？、；：\"\"''（）")
        if len(token) >= 2 {
            keywords = append(keywords, token)
        }
    }

    if len(keywords) > 5 {
        keywords = keywords[:5]
    }

    return keywords
}
```

### 4.3 聚类处理器

```go
package cluster

import (
    "mindx/internal/core"
    "mindx/internal/entity"
)

type Clusterer interface {
    Cluster(conversations []entity.ConversationLog) ([]core.MemoryPoint, error)
}

type KMeansClusterer struct {
    processor       processor.ContentProcessor
    weightCalc      weight.WeightCalculator
    embeddingSvc    *embedding.EmbeddingService
    logger          logging.Logger
}

func NewKMeansClusterer(
    processor processor.ContentProcessor,
    weightCalc weight.WeightCalculator,
    embeddingSvc *embedding.EmbeddingService,
    logger logging.Logger,
) *KMeansClusterer {
    return &KMeansClusterer{
        processor:    processor,
        weightCalc:   weightCalc,
        embeddingSvc: embeddingSvc,
        logger:       logger.Named("clusterer"),
    }
}

func (c *KMeansClusterer) Cluster(conversations []entity.ConversationLog) ([]core.MemoryPoint, error) {
    if len(conversations) == 0 {
        return nil, nil
    }

    points := c.buildMemoryPoints(conversations)
    if len(points) < 2 {
        return points, nil
    }

    vectors := c.extractVectors(points)
    if len(vectors) < 2 {
        return points, nil
    }

    k := c.determineOptimalK(len(vectors))
    clusters := c.performClustering(vectors, k)

    return c.generateClusteredPoints(points, clusters), nil
}

func (c *KMeansClusterer) buildMemoryPoints(conversations []entity.ConversationLog) []core.MemoryPoint {
    points := make([]core.MemoryPoint, 0, len(conversations))

    for _, conv := range conversations {
        content := c.extractContent(conv)
        keywords, _ := c.processor.ExtractKeywords(context.Background(), content)
        summary, _ := c.processor.GenerateSummary(context.Background(), content)

        timeWeight := c.weightCalc.CalculateTimeWeight(conv.EndTime)
        repeatWeight := c.weightCalc.CalculateRepeatWeight(content, keywords)
        emphasisWeight := c.weightCalc.CalculateEmphasisWeight(content)
        totalWeight := c.weightCalc.CalculateTotalWeight(timeWeight, repeatWeight, emphasisWeight, "chat")

        points = append(points, core.MemoryPoint{
            Keywords:       keywords,
            Content:        content,
            Summary:        summary,
            ClusterID:      -1,
            TimeWeight:     timeWeight,
            RepeatWeight:   repeatWeight,
            EmphasisWeight: emphasisWeight,
            TotalWeight:    totalWeight,
            CreatedAt:      conv.StartTime,
            UpdatedAt:      conv.EndTime,
        })
    }

    return points
}

func (c *KMeansClusterer) determineOptimalK(pointCount int) int {
    k := int(math.Sqrt(float64(pointCount) / 2))

    if k < 2 {
        k = 2
    }
    if k > 10 {
        k = 10
    }

    if pointCount < 10 {
        k = 2
    } else if pointCount < 20 {
        k = 3
    } else if pointCount < 50 {
        k = 4
    }

    return k
}

func (c *KMeansClusterer) generateCombinedPoint(points []core.MemoryPoint, clusterID int) (core.MemoryPoint, error) {
    if len(points) == 0 {
        return core.MemoryPoint{}, errors.New("no points provided")
    }

    combined := core.MemoryPoint{
        ClusterID: clusterID,
        Keywords:  c.mergeKeywords(points),
        Content:   c.mergeContent(points),
        Vector:    c.averageVectors(points),
    }

    combined.Summary, _ = c.processor.GenerateSummary(context.Background(), combined.Content)
    combined.TimeWeight = c.averageWeight(points, func(p core.MemoryPoint) float64 { return p.TimeWeight })
    combined.RepeatWeight = c.averageWeight(points, func(p core.MemoryPoint) float64 { return p.RepeatWeight })
    combined.EmphasisWeight = c.averageWeight(points, func(p core.MemoryPoint) float64 { return p.EmphasisWeight })
    combined.TotalWeight = c.averageWeight(points, func(p core.MemoryPoint) float64 { return p.TotalWeight })

    return combined, nil
}
```

### 4.4 记录服务

```go
package memory

type MemoryRecorder struct {
    store         core.Store
    weightCalc    weight.WeightCalculator
    deduplicator  *dedup.Deduplicator
    embeddingSvc  *embedding.EmbeddingService
    logger        logging.Logger
}

func NewMemoryRecorder(
    store core.Store,
    weightCalc weight.WeightCalculator,
    embeddingSvc *embedding.EmbeddingService,
    logger logging.Logger,
) *MemoryRecorder {
    return &MemoryRecorder{
        store:        store,
        weightCalc:   weightCalc,
        deduplicator: dedup.NewDeduplicator(store, logger),
        embeddingSvc: embeddingSvc,
        logger:       logger.Named("recorder"),
    }
}

func (r *MemoryRecorder) Record(ctx context.Context, point core.MemoryPoint) error {
    r.logger.Debug("开始记录记忆", logging.Int("keywords_count", len(point.Keywords)))

    point.CreatedAt = r.ensureCreatedAt(point.CreatedAt)
    point.UpdatedAt = time.Now()

    if len(point.Vector) == 0 {
        point.Vector = r.generateVector(point)
    }

    mergedPoint, wasMerged := r.deduplicator.Deduplicate(&point)
    if wasMerged {
        point = *mergedPoint
    }

    if err := r.storePoint(point); err != nil {
        return apperrors.Wrap(err, apperrors.ErrTypeMemory, "存储记忆失败")
    }

    r.logger.Info("记忆记录成功",
        logging.Int("id", point.ID),
        logging.Int("keywords_count", len(point.Keywords)),
        logging.Float64("total_weight", point.TotalWeight))

    return nil
}

func (r *MemoryRecorder) storePoint(point core.MemoryPoint) error {
    key := fmt.Sprintf("memory_%d", time.Now().UnixNano())
    metadata := map[string]any{"memory_point": point}
    return r.store.Put(key, point.Vector, metadata)
}

func (r *MemoryRecorder) generateVector(point core.MemoryPoint) []float64 {
    if r.embeddingSvc == nil {
        return []float64{}
    }

    combinedText := strings.Join(point.Keywords, " ") + " " + point.Summary + " " + point.Content
    vector, err := r.embeddingSvc.GenerateEmbedding(combinedText)
    if err != nil {
        r.logger.Warn("生成向量失败", logging.Err(err))
        return []float64{}
    }

    return vector
}
```

### 4.5 搜索服务

```go
package memory

type MemorySearcher struct {
    store        core.Store
    embeddingSvc *embedding.EmbeddingService
    logger       logging.Logger
}

func NewMemorySearcher(
    store core.Store,
    embeddingSvc *embedding.EmbeddingService,
    logger logging.Logger,
) *MemorySearcher {
    return &MemorySearcher{
        store:        store,
        embeddingSvc: embeddingSvc,
        logger:       logger.Named("searcher"),
    }
}

func (s *MemorySearcher) Search(ctx context.Context, query string, topN int) ([]core.MemoryPoint, error) {
    s.logger.Debug("开始搜索记忆", logging.String("query", query))

    if s.embeddingSvc == nil {
        return []core.MemoryPoint{}, nil
    }

    queryVector, err := s.embeddingSvc.GenerateEmbedding(query)
    if err != nil {
        return nil, apperrors.Wrap(err, apperrors.ErrTypeMemory, "生成搜索向量失败")
    }

    candidates, err := s.findCandidates(queryVector)
    if err != nil {
        return nil, err
    }

    filtered := s.filterByKeywords(candidates, query)
    sorted := s.sortByWeight(filtered, topN)

    s.logger.Info("记忆搜索完成", logging.Int("found", len(sorted)))
    return sorted, nil
}

func (s *MemorySearcher) findCandidates(queryVector []float64) ([]core.MemoryPoint, error) {
    allMemories, err := s.getAllMemories()
    if err != nil {
        return nil, err
    }

    var candidates []core.MemoryPoint
    for _, mem := range allMemories {
        if len(mem.Vector) == 0 {
            continue
        }

        similarity := utils.CalculateCosineSimilarity(queryVector, mem.Vector)
        if similarity >= 0.5 {
            candidates = append(candidates, mem)
        }
    }

    return candidates, nil
}

func (s *MemorySearcher) getAllMemories() ([]core.MemoryPoint, error) {
    entries, err := s.store.Search(nil, 1000)
    if err != nil {
        return nil, apperrors.Wrap(err, apperrors.ErrTypeMemory, "获取记忆失败")
    }

    points := make([]core.MemoryPoint, 0, len(entries))
    for _, entry := range entries {
        var point core.MemoryPoint
        if err := json.Unmarshal(entry.Metadata, &point); err == nil {
            points = append(points, point)
        }
    }

    return points, nil
}
```

### 4.6 门面模式 - Memory

```go
package memory

type Memory struct {
    recorder   *MemoryRecorder
    searcher   *MemorySearcher
    optimizer  *MemoryOptimizer
    clusterer  cluster.Clusterer
    maintainer *maintenance.Scheduler
    logger     logging.Logger
}

func NewMemory(
    cfg *config.GlobalConfig,
    llmClient *openai.Client,
    logger logging.Logger,
    store core.Store,
    embeddingSvc *embedding.EmbeddingService,
) (*Memory, error) {
    weightConfig := weight.DefaultConfig()
    weightCalc := weight.NewCalculator(weightConfig, store)

    contentProcessor := processor.NewLLMContentProcessor(
        llmClient,
        cfg.Memory.SummaryModel,
        cfg.Memory.KeywordModel,
        logger,
    )

    kmeansClusterer := cluster.NewKMeansClusterer(contentProcessor, weightCalc, embeddingSvc, logger)

    recorder := NewMemoryRecorder(store, weightCalc, embeddingSvc, logger)
    searcher := NewMemorySearcher(store, embeddingSvc, logger)
    optimizer := NewMemoryOptimizer(store, logger)
    scheduler := maintenance.NewScheduler(optimizer, logger)

    mem := &Memory{
        recorder:   recorder,
        searcher:   searcher,
        optimizer:  optimizer,
        clusterer:  kmeansClusterer,
        maintainer: scheduler,
        logger:     logger.Named("memory"),
    }

    logger.Info("记忆系统初始化完成")
    return mem, nil
}

func (m *Memory) Record(point core.MemoryPoint) error {
    return m.recorder.Record(context.Background(), point)
}

func (m *Memory) Search(terms string) ([]core.MemoryPoint, error) {
    return m.searcher.Search(context.Background(), terms, 3)
}

func (m *Memory) Optimize() error {
    return m.optimizer.Optimize()
}

func (m *Memory) ClusterConversations(conversations []entity.ConversationLog) error {
    points, err := m.clusterer.Cluster(conversations)
    if err != nil {
        return err
    }

    for _, point := range points {
        if err := m.recorder.Record(context.Background(), point); err != nil {
            m.logger.Warn("记录聚类结果失败", logging.Err(err))
        }
    }

    return nil
}

func (m *Memory) StartPeriodicMaintenance(interval time.Duration) {
    m.maintainer.Start(interval)
}

func (m *Memory) Close() error {
    m.maintainer.Stop()
    return nil
}
```

---

## 五、配置外置

### 5.1 权重配置

```go
package weight

func DefaultConfig() WeightConfig {
    return WeightConfig{
        TimeDecayFactor:   0.8,
        RepeatBonusFactor: 0.2,
        MaxRepeatWeight:   2.0,
        EmphasisKeywords: map[string]float64{
            "务必":  0.4,
            "关键":  0.35,
            "重要":  0.3,
            "记住":  0.25,
            "一定要": 0.25,
            "千万别": 0.25,
            "must":      0.4,
            "key":       0.35,
            "important": 0.3,
            "remember":  0.25,
            "never":     0.25,
        },
        SceneRatios: map[string]SceneRatio{
            "chat":     {TimeRatio: 0.6, EmphasisRatio: 0.25, RepeatRatio: 0.15},
            "knowledge": {TimeRatio: 0.2, EmphasisRatio: 0.4, RepeatRatio: 0.4},
            "default":  {TimeRatio: 0.4, EmphasisRatio: 0.35, RepeatRatio: 0.25},
        },
    }
}
```

### 5.2 YAML 配置支持

```yaml
memory:
  weight:
    time_decay_factor: 0.8
    repeat_bonus_factor: 0.2
    max_repeat_weight: 2.0
    emphasis_keywords:
      "务必": 0.4
      "关键": 0.35
      "重要": 0.3
    scene_ratios:
      chat:
        time_ratio: 0.6
        emphasis_ratio: 0.25
        repeat_ratio: 0.15
      knowledge:
        time_ratio: 0.2
        emphasis_ratio: 0.4
        repeat_ratio: 0.4
```

---

## 六、重构前后对比

### 6.1 文件结构对比

| 维度           | 重构前 | 重构后   |
| -------------- | ------ | -------- |
| 文件数量       | 1      | 15+      |
| 单文件最大行数 | 1003   | ~150     |
| 单方法最大行数 | 150+   | ~30      |
| 职责数量       | 8      | 1/文件   |
| 依赖数量       | 6      | 2-3/模块 |

### 6.2 测试便利性对比

**重构前**:
```go
func TestMemory(t *testing.T) {
    // 需要 Mock 6 个依赖
    // 需要覆盖 28 个方法
    // 测试用例数量爆炸
}
```

**重构后**:
```go
func TestWeightCalculator(t *testing.T) {
    // 只需 Mock store
    // 独立测试权重计算逻辑
}

func TestContentProcessor(t *testing.T) {
    // 只需 Mock LLM client
    // 独立测试内容处理逻辑
}

func TestClusterer(t *testing.T) {
    // 只需 Mock processor 和 weightCalc
    // 独立测试聚类逻辑
}
```

### 6.3 可维护性对比

| 场景             | 重构前                        | 重构后                        |
| ---------------- | ----------------------------- | ----------------------------- |
| 修改权重算法     | 在 1003 行文件中定位          | 修改 `weight/` 目录下对应文件 |
| 添加新的聚类算法 | 修改 `ClusterConversations`   | 实现 `Clusterer` 接口         |
| 替换 LLM 提供商  | 修改 `generateSummary` 等方法 | 实现 `ContentProcessor` 接口  |
| 调整权重配置     | 修改硬编码值                  | 修改配置文件                  |

---

## 七、实施计划

### 7.1 阶段一：接口定义（2 天）

**任务清单**:
- [ ] 创建 `weight/calculator.go` - 权重计算器接口
- [ ] 创建 `processor/content.go` - 内容处理器接口
- [ ] 创建 `cluster/clusterer.go` - 聚类器接口
- [ ] 创建 `dedup/deduplicator.go` - 去重器接口

### 7.2 阶段二：实现迁移（3 天）

**任务清单**:
- [ ] 实现 `weight/` 目录下所有计算器
- [ ] 实现 `processor/` 目录下所有处理器
- [ ] 实现 `cluster/` 目录下聚类器
- [ ] 实现 `recorder.go`, `searcher.go`, `optimizer.go`
- [ ] 实现 `maintenance/` 目录下维护服务

### 7.3 阶段三：集成测试（2 天）

**任务清单**:
- [ ] 创建新的 `memory.go` 门面
- [ ] 编写单元测试
- [ ] 编写集成测试
- [ ] 性能基准测试

### 7.4 阶段四：清理与文档（1 天）

**任务清单**:
- [ ] 移除旧实现
- [ ] 更新导入路径
- [ ] 更新文档

---

## 八、风险评估

| 风险         | 影响 | 概率 | 缓解措施                     |
| ------------ | ---- | ---- | ---------------------------- |
| 接口设计不当 | 高   | 中   | 充分分析现有代码，渐进式重构 |
| 功能回归     | 高   | 低   | 保持现有测试，增加新测试     |
| 性能下降     | 中   | 低   | 基准测试对比                 |
| 过度设计     | 中   | 中   | 保持简单，避免过度抽象       |

---

## 九、总结

本方案将 1003 行的单一文件拆分为 15+ 个职责单一的模块，遵循单一职责原则和依赖倒置原则。

**核心改进**:
- 每个模块职责单一，易于理解和维护
- 通过接口解耦，支持灵活扩展
- 配置外置，避免硬编码
- 测试独立，降低测试复杂度

**建议**:
- 采用渐进式重构，保持系统稳定
- 先定义接口，再迁移实现
- 持续运行测试，确保功能正确

---

**文档版本**: 1.0  
**最后更新**: 2026-02-23
